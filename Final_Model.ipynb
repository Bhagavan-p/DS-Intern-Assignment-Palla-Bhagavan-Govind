{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "0584136d-6b6c-4e94-9c5d-8f3c57a45428",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries for analysis and visualisation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "#import libraries for ML-Model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score, make_scorer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from sklearn.preprocessing import  MinMaxScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from scipy.stats import boxcox\n",
    "from scipy.stats import boxcox_normmax\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "import pickle\n",
    "\n",
    "## Library of warnings would assist in ignoring warnings issued\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0a5f59cb-448d-4452-810d-73d5dc613972",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3cd631c6-eb58-459e-9089-61be0e878370",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['timestamp'] = pd.to_datetime(data['timestamp'], errors='coerce')\n",
    "for col in data.columns:\n",
    "    if data[col].dtype == 'object' and col != 'timestamp':\n",
    "        data[col] = pd.to_numeric(data[col], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7d8be8b9-3a5e-44fa-a3ab-95597f07bb8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting the months, days, hours, minutes from date\n",
    "data['hour'] = data['timestamp'].dt.hour\n",
    "data['minute'] = data['timestamp'].dt.minute\n",
    "data['day'] = data['timestamp'].dt.day\n",
    "data['weekday'] = data['timestamp'].dt.weekday  # Monday=0, Sunday=6\n",
    "data['month'] = data['timestamp'].dt.month\n",
    "\n",
    "\n",
    "# Droping the original timestamp column\n",
    "data.drop(columns=['timestamp'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "348fad75-a1ed-4256-8c51-4d93fbca376a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[data['equipment_energy_consumption'] >= 0]\n",
    "\n",
    "invalid_negative_columns = ['lighting_energy', 'zone1_humidity',\n",
    "       'zone2_humidity', 'zone3_humidity', 'zone4_humidity', 'zone5_humidity', 'zone6_humidity', 'zone7_humidity',\n",
    "       'zone8_humidity', 'zone9_humidity', 'outdoor_humidity', 'wind_speed', 'visibility_index']\n",
    "data[invalid_negative_columns] = data[invalid_negative_columns].applymap(lambda x: np.nan if x < 0 else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e5324631-f0a2-42e5-ba47-27d4e9ce9a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in data.columns:\n",
    "    if column != 'equipment_energy_consumption':\n",
    "        mean_value = data[column].median()\n",
    "        data[column].fillna(mean_value, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "5f2e9010-0a6c-4d21-afda-463ebfb6138d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "1ef30517-73ff-4dfd-96f7-ab9d0318792d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handling Outliers & Outlier treatments\n",
    "for ftr in data.columns:\n",
    "  q_25= np.percentile(data[ftr], 25)\n",
    "  q_75 = np.percentile(data[ftr], 75)\n",
    "  iqr = q_75 - q_25\n",
    "  # calculate the outlier cutoff\n",
    "  cut_off = iqr * 1.5\n",
    "  lower = q_25 - cut_off\n",
    "  upper = q_75 + cut_off\n",
    "  # identify outliers\n",
    "  outliers = [x for x in data[ftr] if x < lower or x > upper]\n",
    "  #removing outliers\n",
    "  if len(outliers)!=0:\n",
    "    def bin(row):\n",
    "      if row[ftr]> upper:\n",
    "        return upper\n",
    "      if row[ftr] < lower:\n",
    "        return lower\n",
    "      else:\n",
    "        return row[ftr]\n",
    "    data[ftr] =  data.apply (lambda row: bin(row), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "2510b9c5-5fcb-4a93-819e-5864bb0e3680",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Manipulate Features to minimize feature correlation\n",
    "# create new features\n",
    "# create a column average zone temperature based on all temperature\n",
    "data['avg_zone_temperature'] = data[[f'zone{i}_temperature' for i in range(1, 10)]].mean(axis=1)\n",
    "\n",
    "#create a column of the difference between outside and zone temperature\n",
    "data['Temperature_difference']=abs(data['avg_zone_temperature']-data['outdoor_temperature'])\n",
    "\n",
    "#create a column average zone humidity\n",
    "data['avg_zone_humidity'] = data[[f'zone{i}_humidity' for i in range(1, 10)]].mean(axis=1)\n",
    "\n",
    "#create a column of the difference between zone and outside building humidity\n",
    "data['Humidity_difference']=abs(data['avg_zone_humidity']-data['outdoor_humidity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "729bb351-93ac-4689-a429-cdca1a5ba626",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=data[[i for i in data.describe().columns if i not in ['lighting_energy', 'zone9_temperature', 'zone6_temperature', 'avg_zone_humidity',\n",
    "        'outdoor_temperature', 'zone9_humidity', 'Temperature_difference', 'zone8_humidity', 'zone8_temperature', 'zone7_humidity',\n",
    "        'zone7_temperature', 'zone6_humidity', 'zone5_humidity', 'avg_zone_temperature', 'outdoor_humidity', 'zone1_temperature',\n",
    "        'atmospheric_pressure', 'zone3_humidity', 'zone5_temperature', 'zone3_temperature', 'zone1_humidity', 'zone4_temperature',\n",
    "        'zone4_humidity', 'zone2_humidity', 'zone2_temperature', 'random_variable1', 'random_variable2', 'visibility_index']]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "1ec42c6a-5b4d-4b25-bdee-69670b6081fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Determine the optimal lambda value for the Box-Cox transformation\n",
    "optimal_lambda = boxcox_normmax(data['equipment_energy_consumption'])\n",
    "\n",
    "# Apply the Box-Cox transformation to the 'equipment_energy_consumption' column using the optimal lambda\n",
    "data['equipment_energy_consumption'] = boxcox(data['equipment_energy_consumption'], optimal_lambda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "89c47d90-1eeb-4446-b667-2c5dd0a0753e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform Your data\n",
    "data['wind_speed']=data['wind_speed'].apply(lambda x:np.log10(x+1))\n",
    "data['Humidity_difference'] = data['Humidity_difference'] ** 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c867ba1e-78d3-4335-870a-d0db8b5bc606",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop(columns=['equipment_energy_consumption'])\n",
    "y = data['equipment_energy_consumption']\n",
    "split_idx = int(0.8 * len(data))  # 80% train, 20% test\n",
    "X_train, y_train = X[:split_idx], y[:split_idx]\n",
    "X_test, y_test = X[split_idx:], y[split_idx:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "3d55455b-f5ff-4d5e-aa22-b5021c8fe3de",
   "metadata": {},
   "outputs": [],
   "source": [
    "if isinstance(y_train, np.ndarray):\n",
    "    y_train = pd.Series(y_train, name='equipment_energy_consumption', index=X_train.index)\n",
    "\n",
    "# Combine features and target\n",
    "train = pd.concat([X_train, y_train], axis=1)\n",
    "if isinstance(y_test, np.ndarray):\n",
    "    y_test = pd.Series(y_test, name='equipment_energy_consumption', index=X_train.index)\n",
    "\n",
    "# Combine features and target\n",
    "test = pd.concat([X_test, y_test], axis=1)\n",
    "\n",
    "for lag in [1, 2, 3, 4, 5, 6]: \n",
    "    train[f'energy_lag_{lag}'] = train['equipment_energy_consumption'].shift(lag)\n",
    "    test[f'energy_lag_{lag}'] = test['equipment_energy_consumption'].shift(lag)\n",
    "\n",
    "for i in [3, 6, 12]: \n",
    "    train[f'energy_rolling_{i}h_mean'] = train['equipment_energy_consumption'].shift(1).rolling(i).mean()\n",
    "    test[f'energy_rolling_{i}h_mean'] = test['equipment_energy_consumption'].shift(1).rolling(i).mean()\n",
    "    \n",
    "train = train.dropna()\n",
    "test = test.dropna()\n",
    "X_train = train.drop(columns='equipment_energy_consumption')\n",
    "y_train = train['equipment_energy_consumption']\n",
    "X_test = test.drop(columns='equipment_energy_consumption')\n",
    "y_test = test['equipment_energy_consumption']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "c0626c1c-8e21-497b-818c-42eeb524fbf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling your data\n",
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "e8c0bbb4-1a9f-4858-8cfe-98ae41fa1c09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: RMSE = 0.0981, R² = 0.7732\n",
      "Test : RMSE = 0.0976, R² = 0.6680\n"
     ]
    }
   ],
   "source": [
    "#ExtraTreesRegressor\n",
    "ETR_model = ExtraTreesRegressor( n_estimators=500,\n",
    "    max_depth=100,            \n",
    "    min_samples_split=50,\n",
    "    random_state=42,\n",
    "    n_jobs=-1)\n",
    "ETR_model.fit(X_train, y_train)\n",
    "train_preds = ETR_model.predict(X_train)\n",
    "test_preds = ETR_model.predict(X_test)\n",
    "train_rmse = np.sqrt(mean_squared_error(y_train, train_preds))\n",
    "test_rmse = np.sqrt(mean_squared_error(y_test, test_preds))\n",
    "train_r2 = r2_score(y_train, train_preds)\n",
    "test_r2 = r2_score(y_test, test_preds)\n",
    "print(f\"Train: RMSE = {train_rmse:.4f}, R² = {train_r2:.4f}\")\n",
    "print(f\"Test : RMSE = {test_rmse:.4f}, R² = {test_r2:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "88f5f2e2-1062-4c76-bc67-79acf0e69e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'finalized_model.sav'\n",
    "pickle.dump(ETR_model, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "45411ca8-3daa-4761-9dac-c2edbf71a6c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6679815986589731\n"
     ]
    }
   ],
   "source": [
    "loaded_model = pickle.load(open(filename, 'rb'))\n",
    "y_pred_best = loaded_model.predict(X_test)\n",
    "print(r2_score(y_test, y_pred_best))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bbb2d62-a0d2-4d1c-9e51-1cbfa22227f5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
